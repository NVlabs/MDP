python -m torch.distributed.launch --nproc_per_node=4 --use_env main_full_global_latency.py --model deit_base_distilled_patch16_224 --epochs 50 --num_workers 10 --batch-size 128 --data-path /raid/ImageNet2012/ImageNet2012 --data-set IMNET --lr 1e-4 --output_dir /result/ --amp --input-size 224 --seed 1 --pruning_config=pruning_configs/group8_m23_m09.json --prune_per_iter=32 --kl_loss_coeff=100000 --original_loss_coeff=1.0 --student_eval=True --dist-eval --pruning --prune_dict '{"Global":39000}' --interval_prune 100 --pretrained --distillation-type hard --latency_regularization 5e-4 --latency_target 0.54 --latency_look_up_table latency_head.json --pruning_exit