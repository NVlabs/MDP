
python -m torch.distributed.launch --nproc_per_node=4 --use_env main_full_global_latency.py --model deit_base_distilled_patch16_224 --epochs 50 --num_workers 10 --batch-size 128 --data-path /raid/ImageNet2012/ImageNet2012 --data-set IMNET --lr 1e-5 --output_dir /result --amp --input-size 224 --seed 1 --pruning_config=pruning_configs/group8_m23_m09.json --prune_per_iter=32 --kl_loss_coeff=100000 --original_loss_coeff=1.0 --student_eval=True --dist-eval --pruning --prune_dict '{"Global":39000}' --interval_prune 200 --pretrained --distillation-type hard --latency_regularization 5e-4 --latency_target 0.39 --latency_look_up_table latency_head.json --pruning_steps 80 --name_ext 80x200_lr1e-5  --pruning_exit


python -m torch.distributed.launch --nproc_per_node=4 --use_env main_full_global_latency.py --model deit_base_distilled_patch16_224 --epochs 50 --num_workers 10 --batch-size 128 --data-path /raid/ImageNet2012/ImageNet2012 --data-set IMNET --lr 1e-5 --output_dir /result --amp --input-size 224 --seed 1 --pruning_config=pruning_configs/group8_m23_m09.json --prune_per_iter=32 --kl_loss_coeff=100000 --original_loss_coeff=1.0 --student_eval=True --dist-eval --pruning --prune_dict '{"Global":39000}' --interval_prune 200 --pretrained --distillation-type hard --latency_regularization 5e-4 --latency_target 0.19 --latency_look_up_table latency_head.json --pruning_steps 80 --name_ext 80x200_lr1e-5  --pruning_exit

python -m torch.distributed.launch --nproc_per_node=4 --use_env main_full_global_latency.py --model deit_base_distilled_patch16_224 --epochs 50 --num_workers 10 --batch-size 128 --data-path /raid/ImageNet2012/ImageNet2012 --data-set IMNET --lr 1e-5 --output_dir /result --amp --input-size 224 --seed 1 --pruning_config=pruning_configs/group8_m23_m09.json --prune_per_iter=32 --kl_loss_coeff=100000 --original_loss_coeff=1.0 --student_eval=True --dist-eval --pruning --prune_dict '{"Global":39000}' --interval_prune 200 --pretrained --distillation-type hard --latency_regularization 5e-4 --latency_target 0.54 --latency_look_up_table latency_head.json --pruning_steps 80 --name_ext 80x200_lr1e-5  --pruning_exit


python -m torch.distributed.launch --nproc_per_node=4 --use_env main_full_global_latency.py --model deit_base_distilled_patch16_224 --epochs 50 --num_workers 10 --batch-size 128 --data-path /raid/ImageNet2012/ImageNet2012 --data-set IMNET --lr 1e-5 --output_dir /result --amp --input-size 224 --seed 1 --pruning_config=pruning_configs/group8_m23_m09.json --prune_per_iter=32 --kl_loss_coeff=100000 --original_loss_coeff=1.0 --student_eval=True --dist-eval --pruning --prune_dict '{"Global":39000}' --interval_prune 200 --pretrained --distillation-type hard --latency_regularization 5e-4 --latency_target 0.50 --latency_look_up_table latency_head.json --pruning_steps 80 --name_ext 80x200_lr1e-5  --pruning_exit


## FLOPs Target

python -m torch.distributed.launch --nproc_per_node=4 --use_env main_full_global_latency.py --model deit_base_distilled_patch16_224 --epochs 50 --num_workers 10 --batch-size 128 --data-path /raid/ImageNet2012/ImageNet2012 --data-set IMNET --lr 1e-5 --output_dir /result --amp --input-size 224 --seed 1 --pruning_config=pruning_configs/group8_m23_m09.json --prune_per_iter=32 --kl_loss_coeff=100000 --original_loss_coeff=1.0 --student_eval=True --dist-eval --pruning --prune_dict '{"Global":39000}' --interval_prune 200 --pretrained --distillation-type hard --latency_regularization 5e-4 --latency_target 0.23 --latency_look_up_table latency_head.json --pruning_steps 80 --name_ext FLOPs_80x200_lr1e-5  --pruning_exit

python -m torch.distributed.launch --nproc_per_node=4 --use_env main_full_global_latency.py --model deit_base_distilled_patch16_224 --epochs 50 --num_workers 10 --batch-size 128 --data-path /raid/ImageNet2012/ImageNet2012 --data-set IMNET --lr 1e-5 --output_dir /result --amp --input-size 224 --seed 1 --pruning_config=pruning_configs/group8_m23_m09.json --prune_per_iter=32 --kl_loss_coeff=100000 --original_loss_coeff=1.0 --student_eval=True --dist-eval --pruning --prune_dict '{"Global":39000}' --interval_prune 200 --pretrained --distillation-type hard --latency_regularization 5e-4 --latency_target 0.07 --latency_look_up_table latency_head.json --pruning_steps 80 --name_ext FLOPs_80x200_lr1e-5  --pruning_exit
