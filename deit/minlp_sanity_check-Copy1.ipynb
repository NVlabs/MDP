{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyomo.environ import *\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from scipy.interpolate import RegularGridInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4608"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "96 * 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB, HEAD, QK, V, MLP = 768,12,64,64,3072\n",
    "all_variable_specs = {\n",
    "    \"EMB\": [768, 32, 768//32+1],\n",
    "    \"HEAD\": [12, 1, 12//1+1],\n",
    "    \"QK\": [64, 2, 64//2+1],\n",
    "    \"V\": [64, 2, 64//2+1],\n",
    "    \"MLP\": [3072, 32, 3072//32+1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_file = \"latency_head.json\"\n",
    "with open(latency_file) as json_file:\n",
    "    measurement = json.load(json_file)\n",
    "EMB = np.arange(4)*256\n",
    "head = np.array([1,3,6,9,12])\n",
    "QK = np.array([1,16,32,48,64])\n",
    "V = np.array([1,16,32,48,64])\n",
    "MLP = (np.arange(25))*128\n",
    "data = np.zeros([4,5,5,5,25])\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        for k1 in range(5):\n",
    "            for k2 in range(5):\n",
    "                for l in range(25):\n",
    "                    e = EMB[i+1]\n",
    "                    q_h = head[j]\n",
    "                    q = QK[k1]\n",
    "                    v = V[k2]\n",
    "                    if MLP[l]:\n",
    "                        h = MLP[l]\n",
    "                    else:\n",
    "                        h = 1\n",
    "                    data[i+1,j,k1,k2,l] = measurement['EMB_'+str(e)]['QK_'+str(q_h)+'_'+str(q)]['V_'+str(v)]['MLP_'+str(h)]\n",
    "latency_look_up_table = RegularGridInterpolator((EMB, head, QK, V, MLP), data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress 0/25\n",
      "progress 1/25\n",
      "progress 2/25\n",
      "progress 3/25\n",
      "progress 4/25\n",
      "progress 5/25\n",
      "progress 6/25\n",
      "progress 7/25\n",
      "progress 8/25\n",
      "progress 9/25\n",
      "progress 10/25\n",
      "progress 11/25\n",
      "progress 12/25\n",
      "progress 13/25\n",
      "progress 14/25\n",
      "progress 15/25\n",
      "progress 16/25\n",
      "progress 17/25\n",
      "progress 18/25\n",
      "progress 19/25\n",
      "progress 20/25\n",
      "progress 21/25\n",
      "progress 22/25\n",
      "progress 23/25\n",
      "progress 24/25\n"
     ]
    }
   ],
   "source": [
    "# Define index ranges and strides\n",
    "emb_idx_range = np.arange(all_variable_specs[\"EMB\"][2])\n",
    "head_idx_range = np.arange(all_variable_specs[\"HEAD\"][2])\n",
    "qk_idx_range = np.arange(all_variable_specs[\"QK\"][2])\n",
    "v_idx_range = np.arange(all_variable_specs[\"V\"][2])\n",
    "mlp_idx_range = np.arange(all_variable_specs[\"MLP\"][2])\n",
    "\n",
    "# Calculate and fill latency table\n",
    "for emb_idx in emb_idx_range:\n",
    "    print(f\"progress {emb_idx}/{all_variable_specs['EMB'][2]}\")\n",
    "    \n",
    "    emb_values = np.maximum(emb_idx * all_variable_specs[\"EMB\"][1], 1)\n",
    "    head_values = np.maximum(head_idx_range * all_variable_specs[\"HEAD\"][1], 1)\n",
    "    qk_values = np.maximum(qk_idx_range * all_variable_specs[\"QK\"][1], 1)\n",
    "    v_values = np.maximum(v_idx_range * all_variable_specs[\"V\"][1], 1)\n",
    "    mlp_values = np.maximum(mlp_idx_range * all_variable_specs[\"MLP\"][1], 1)\n",
    "    \n",
    "    emb_grid, head_grid, qk_grid, v_grid, mlp_grid = np.meshgrid(emb_values, head_values, qk_values, v_values, mlp_values, indexing='ij')\n",
    "\n",
    "    dim_vecs = np.vstack([emb_grid.ravel(), head_grid.ravel(), qk_grid.ravel(), v_grid.ravel(), mlp_grid.ravel()]).T\n",
    "    latency_values = latency_look_up_table(dim_vecs)\n",
    "    \n",
    "    latency_table[emb_idx, :, :, :, :] = latency_values.reshape(all_variable_specs[\"HEAD\"][2], all_variable_specs[\"QK\"][2], all_variable_specs[\"V\"][2], all_variable_specs[\"MLP\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025570660829544067\n",
      "[0.02557066]\n"
     ]
    }
   ],
   "source": [
    "test_emb = 6\n",
    "test_head = 11\n",
    "test_qk = 16\n",
    "test_v = 30\n",
    "test_mlp = 40\n",
    "\n",
    "# Convert test dimensions to the scale of the data\n",
    "test_dim_vec = np.array([\n",
    "    max(test_emb * all_variable_specs[\"EMB\"][1], 1),\n",
    "    max(test_head * all_variable_specs[\"HEAD\"][1], 1),\n",
    "    max(test_qk * all_variable_specs[\"QK\"][1], 1),\n",
    "    max(test_v * all_variable_specs[\"V\"][1], 1),\n",
    "    max(test_mlp * all_variable_specs[\"MLP\"][1], 1)\n",
    "])\n",
    "\n",
    "# Print the latency table value at the specified indices\n",
    "print(latency_table[test_emb, test_head, test_qk, test_v, test_mlp])\n",
    "\n",
    "# Interpolate to find the latency value\n",
    "latency_value = latency_look_up_table(test_dim_vec)\n",
    "print(latency_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"minlp_latency_table.pkl\", \"wb\") as f:\n",
    "    pickle.dump(latency_table, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latency_table_shape = tuple([x[2] for x in all_variable_specs.values()])\n",
    "# latency_table = np.zeros(latency_table_shape)\n",
    "\n",
    "# for emb_idx in range(all_variable_specs[\"EMB\"][2]):\n",
    "#     print(f\"progress {emb_idx}/{all_variable_specs['EMB'][2]}\")\n",
    "#     for head_idx in range(all_variable_specs[\"HEAD\"][2]):\n",
    "#         for qk_idx in range(all_variable_specs[\"QK\"][2]):\n",
    "#             for v_idx in range(all_variable_specs[\"V\"][2]):\n",
    "#                 for mlp_idx in range(all_variable_specs[\"MLP\"][2]):\n",
    "                    \n",
    "#                     emb = max(emb_idx*all_variable_specs[\"EMB\"][1], 1)\n",
    "#                     head = max(head_idx*all_variable_specs[\"HEAD\"][1], 1)\n",
    "#                     qk = max(qk_idx*all_variable_specs[\"QK\"][1], 1)\n",
    "#                     v = max(v_idx*all_variable_specs[\"V\"][1], 1)\n",
    "#                     mlp = max(mlp_idx*all_variable_specs[\"MLP\"][1], 1)\n",
    "                    \n",
    "#                     dim_vec = np.array([emb,head,qk,v,mlp])\n",
    "#                     latency_table[emb_idx, head_idx, qk_idx, v_idx, mlp_idx] = latency_look_up_table(dim_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define model and variables\n",
    "# model = ConcreteModel()\n",
    "# for var_type, var_spec in all_variable_specs.items():\n",
    "#     dummies = list(range(all_variable_specs[var_type][2]))\n",
    "#     setattr(model, f\"{var_type}_vars\", Var(dummies, domain=Binary))\n",
    "\n",
    "# model.unique_constraint = ConstraintList()\n",
    "# importance = 0\n",
    "# # Define constraint and importance\n",
    "# for var_type, var_spec in all_variable_specs.items():\n",
    "#     cur_vars = list([getattr(model, f\"{var_type}_vars\")[i] for i in range(all_variable_specs[var_type][2])])\n",
    "#     model.unique_constraint.add(sum(cur_vars) == 1)\n",
    "#     random_importance = np.abs(np.random.randn(all_variable_specs[var_type][2])) * 100\n",
    "#     importance += sum(cur_vars[i] * random_importance[i] for i in range(all_variable_specs[var_type][2]))\n",
    "\n",
    "# model.obj = Objective(expr=importance, sense=maximize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ConcreteModel()\n",
    "# model.x = Var(bounds=(1.0,10.0),initialize=5.0)\n",
    "# model.y = Var(within=Binary)\n",
    "# model.c1 = Constraint(expr=(model.x-4.0)**2 - model.x <= 50.0*(1-model.y))\n",
    "# model.c2 = Constraint(expr=model.x*log(model.x)+5.0 <= 50.0*(model.y))\n",
    "# model.objective = Objective(expr=model.x, sense=minimize)\n",
    "# SolverFactory('mindtpy').solve(model, mip_solver='glpk', nlp_solver='ipopt') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trivial GLPK Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConcreteModel()\n",
    "# Define variables\n",
    "variable_slices_by_type = {}\n",
    "counter = 0\n",
    "for var_type, var_spec in all_variable_specs.items():\n",
    "    variable_slices_by_type[var_type] = (counter, counter+all_variable_specs[var_type][2])\n",
    "    counter += all_variable_specs[var_type][2]\n",
    "\n",
    "all_items = list(range(counter))\n",
    "model.decision_vars = Var(all_items, domain=Binary)\n",
    "\n",
    "# Define importance and constraint\n",
    "importance = 0\n",
    "model.group_unique_constraint = ConstraintList()\n",
    "\n",
    "for var_type, var_spec in all_variable_specs.items():\n",
    "    cur_decision_vars = [model.decision_vars[k] for k in range(variable_slices_by_type[var_type][0], variable_slices_by_type[var_type][1])]\n",
    "    model.group_unique_constraint.add(sum(cur_decision_vars[i] for i in list(range(len(cur_decision_vars)))) == 1)\n",
    "    random_importance = np.abs(np.random.randn(all_variable_specs[var_type][2])) * 100\n",
    "    importance += sum(cur_decision_vars[i] * random_importance[i] for i in range(len(cur_decision_vars)))\n",
    "\n",
    "model.obj = Objective(expr=importance, sense=maximize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Problem': [{'Name': 'unknown', 'Lower bound': 1296.39062795143, 'Upper bound': 1296.39062795143, 'Number of objectives': 1, 'Number of constraints': 6, 'Number of variables': 202, 'Number of nonzeros': 202, 'Sense': 'maximize'}], 'Solver': [{'Status': 'ok', 'Termination condition': 'optimal', 'Statistics': {'Branch and bound': {'Number of bounded subproblems': '1', 'Number of created subproblems': '1'}}, 'Error rc': 0, 'Time': 0.032980918884277344}], 'Solution': [OrderedDict([('number of solutions', 0), ('number of solutions displayed', 0)])]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solver = SolverFactory('mindtpy')\n",
    "solver = SolverFactory('glpk')\n",
    "solver.solve(model)\n",
    "# results = solver.solve(model, strategy='OA', init_strategy='FP', mip_solver='glpk', nlp_solver='ipopt', tee=True) \n",
    "# results = solver.solve(model, strategy='OA', init_strategy='FP', mip_solver='glpk', nlp_solver='ipopt') \n",
    "# results = solver.solve(model) \n",
    "# results = solver.solve(model, mip_solver='glpk', nlp_solver='ipopt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMB [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "HEAD [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "QK [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "V [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "MLP [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for var_type, var_spec in all_variable_specs.items():\n",
    "    indices = list(range(variable_slices_by_type[var_type][0], variable_slices_by_type[var_type][1]))\n",
    "    cur_decision_vars = [model.decision_vars[k] for k in indices]\n",
    "    cur_decision_vars_value = [x.value for x in cur_decision_vars]\n",
    "    print(var_type, cur_decision_vars_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MINLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 13, 33, 33, 97)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latency_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[768, 32, 25]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_variable_specs[\"EMB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConcreteModel()\n",
    "# Define variables\n",
    "variable_slices_by_type = {}\n",
    "counter = 0\n",
    "for var_type, var_spec in all_variable_specs.items():\n",
    "    variable_slices_by_type[var_type] = (counter, counter+all_variable_specs[var_type][2])\n",
    "    counter += all_variable_specs[var_type][2]\n",
    "\n",
    "all_items = list(range(counter))\n",
    "model.decision_vars = Var(all_items, domain=Binary)\n",
    "\n",
    "# Define importance and constraint\n",
    "importance = 0\n",
    "model.group_unique_constraint = ConstraintList()\n",
    "\n",
    "for var_type, var_spec in all_variable_specs.items():\n",
    "    cur_decision_vars = [model.decision_vars[k] for k in range(variable_slices_by_type[var_type][0], variable_slices_by_type[var_type][1])]\n",
    "    model.group_unique_constraint.add(sum(cur_decision_vars[i] for i in list(range(len(cur_decision_vars)))) == 1)\n",
    "    random_importance = np.abs(np.random.randn(all_variable_specs[var_type][2])) * 100\n",
    "    importance += sum(cur_decision_vars[i] * random_importance[i] for i in range(len(cur_decision_vars)))\n",
    "\n",
    "# Add latency constraint\n",
    "emb_vectors = np.array([model.decision_vars[k] for k in range(variable_slices_by_type[\"EMB\"][0], variable_slices_by_type[\"EMB\"][1])])\n",
    "head_vectors = np.array([model.decision_vars[k] for k in range(variable_slices_by_type[\"HEAD\"][0], variable_slices_by_type[\"HEAD\"][1])])\n",
    "qk_vectors = np.array([model.decision_vars[k] for k in range(variable_slices_by_type[\"QK\"][0], variable_slices_by_type[\"QK\"][1])])\n",
    "v_vectors = np.array([model.decision_vars[k] for k in range(variable_slices_by_type[\"V\"][0], variable_slices_by_type[\"V\"][1])])\n",
    "mlp_vectors = np.array([model.decision_vars[k] for k in range(variable_slices_by_type[\"MLP\"][0], variable_slices_by_type[\"MLP\"][1])])\n",
    "\n",
    "# grid_emb, grid_head, grid_qk, grid_v, grid_mlp = np.meshgrid(emb_vectors, head_vectors, qk_vectors, v_vectors, mlp_vectors, indexing='ij')\n",
    "# T = grid_emb * grid_head * grid_qk * grid_v * grid_mlp\n",
    "# T = np.tensordot(np.tensordot(np.tensordot(np.tensordot(emb_vectors, head_vectors, axes=0), qk_vectors, axes=0), v_vectors, axes=0), mlp_vectors, axes=0)\n",
    "T1 = np.tensordot(emb_vectors, mlp_vectors, axes=0)\n",
    "T2 = np.tensordot(np.tensordot(emb, v_vectors, axes=0), mlp_vectors, axes=0)\n",
    "latency_expr = sum(T * latency_table)\n",
    "model.latency_constraint = Constraint(expr=latency_expr <= capacity)\n",
    "model.obj = Objective(expr=importance, sense=maximize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Problem': [{'Name': 'unknown', 'Lower bound': 1308.26414625436, 'Upper bound': 1308.26414625436, 'Number of objectives': 1, 'Number of constraints': 6, 'Number of variables': 202, 'Number of nonzeros': 202, 'Sense': 'maximize'}], 'Solver': [{'Status': 'ok', 'Termination condition': 'optimal', 'Statistics': {'Branch and bound': {'Number of bounded subproblems': '1', 'Number of created subproblems': '1'}}, 'Error rc': 0, 'Time': 0.06783676147460938}], 'Solution': [OrderedDict([('number of solutions', 0), ('number of solutions displayed', 0)])]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solver = SolverFactory('mindtpy')\n",
    "solver = SolverFactory('glpk')\n",
    "solver.solve(model)\n",
    "# results = solver.solve(model, strategy='OA', init_strategy='FP', mip_solver='glpk', nlp_solver='ipopt', tee=True) \n",
    "# results = solver.solve(model, strategy='OA', init_strategy='FP', mip_solver='glpk', nlp_solver='ipopt') \n",
    "# results = solver.solve(model) \n",
    "# results = solver.solve(model, mip_solver='glpk', nlp_solver='ipopt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 13, 33, 33, 97)\n"
     ]
    }
   ],
   "source": [
    "print(latency_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vectors = np.random.randn(25, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.tensordot(emb_vectors, latency_table, axes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1, 25, 13, 33, 33, 97)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 13, 33, 33, 97)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize your vectors (replace with your actual data)\n",
    "a = np.random.rand(25)\n",
    "b = np.random.rand(13)\n",
    "c = np.random.rand(33)\n",
    "d = np.random.rand(33)\n",
    "e = np.random.rand(97)\n",
    "\n",
    "# Create the meshgrid for each vector\n",
    "# Note: `numpy.meshgrid` creates coordinate matrices, so we need to use `indexing='ij'` for multi-dimensional grids\n",
    "grid_a, grid_b, grid_c, grid_d, grid_e = np.meshgrid(a, b, c, d, e, indexing='ij')\n",
    "\n",
    "# Calculate the tensor T\n",
    "T = grid_a * grid_b * grid_c * grid_d * grid_e\n",
    "\n",
    "# T now has the shape (25, 13, 33, 33, 97)\n",
    "print(T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029128482823468138"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[13, 6, 7, 8, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029128482823468138"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[13]*b[6]*c[7]*d[8]*e[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 13, 33, 33, 97)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize your vectors (replace with your actual data)\n",
    "a = np.random.rand(25)\n",
    "b = np.random.rand(13)\n",
    "c = np.random.rand(33)\n",
    "d = np.random.rand(33)\n",
    "e = np.random.rand(97)\n",
    "\n",
    "# Create the meshgrid for each vector\n",
    "# We need to create a grid that has the same dimensionality as each vector\n",
    "T = np.tensordot(np.tensordot(np.tensordot(np.tensordot(a, b, axes=0), c, axes=0), d, axes=0), e, axes=0)\n",
    "\n",
    "# T now has the shape (25, 13, 33, 33, 97)\n",
    "print(T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
